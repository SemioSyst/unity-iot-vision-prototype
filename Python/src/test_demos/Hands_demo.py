import cv2, time, math
import mediapipe as mp

# ---------- Camera config ----------
CAM_INDEX = 0
W, H = 1280, 720
TARGET_FPS = 30            # ä»…ä½œè¯·æ±‚ï¼Œæ˜¯å¦æˆåŠŸéœ€æµ‹é‡

# ---------- MediaPipe config ----------
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

# æ£€æµ‹/è·Ÿè¸ªé˜ˆå€¼ï¼šè¶Šé«˜è¶Šä¸¥æ ¼ï¼ˆæ›´ç¨³ä½†æ›´å®¹æ˜“æ¼ï¼‰
DETECT_CONF = 0.6
TRACK_CONF  = 0.6
MAX_HANDS   = 2
MODEL_COMPLEXITY = 0       # 0 æ›´å¿«ï¼Œ1/2 æ›´ç²¾ç»†

# ---------- Utils ----------
# åœ¨å›¾åƒä¸Šç»˜åˆ¶ FPS
def draw_fps(img, fps):
    cv2.putText(img, f"FPS: {fps:.1f}", (12, 28),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)

# åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡æ³¨å·¦æ‰‹è¿˜æ˜¯å³æ‰‹ä»¥åŠç½®ä¿¡åº¦
def draw_handedness(img, results):
    # æ— æ£€æµ‹åˆ°æ‰‹åˆ™è·³è¿‡
    if not results.multi_handedness or not results.multi_hand_landmarks:
        return
    # éå†æ¯åªæ‰‹
    for handedness, lm in zip(results.multi_handedness, results.multi_hand_landmarks):
        label = handedness.classification[0].label  # 'Left' or 'Right'
        score = handedness.classification[0].score  # ç½®ä¿¡åº¦
        # å–æ‰‹è…•ç‚¹ä½œä¸ºæ ‡æ³¨ä½ç½®
        h, w = img.shape[:2] # å›¾åƒå°ºå¯¸
        x = int(lm.landmark[0].x * w) # æ‰‹è…• x åæ ‡
        y = int(lm.landmark[0].y * h) # æ‰‹è…• y åæ ‡
        cv2.putText(img, f"{label} {score:.2f}", (x+10, y-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)

def landmarks_to_list(lmks, w, h):
    """æŠŠ 21 ç‚¹è½¬æˆä¾¿äºå‘å¾€ Unity çš„ç»“æ„ï¼ˆå½’ä¸€åŒ– & åƒç´ åæ ‡éƒ½è¿”å›ï¼‰"""
    pts = [] # å­˜æ”¾ç‚¹çš„åˆ—è¡¨
    for lm in lmks.landmark:
        # é€šè¿‡dictå­˜å‚¨æ¯ä¸ªç‚¹çš„ä¿¡æ¯
        pts.append({
            "x": lm.x, "y": lm.y, "z": lm.z,            # å½’ä¸€åŒ–åæ ‡ï¼ˆ0..1ï¼‰
            "px": int(lm.x * w), "py": int(lm.y * h),   # åƒç´ åæ ‡
            "vz": lm.z                                   # ç›¸å¯¹æ·±åº¦ï¼ˆè´Ÿæ•°æ›´é è¿‘ï¼‰
        })
    return pts

# ---------- Main loop ----------
def main():
    cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)  # Windowsä¸Šç”¨ DSHOW æ›´ç¨³
    cap.set(cv2.CAP_PROP_FRAME_WIDTH,  W)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, H)
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)

    hands = mp_hands.Hands(
        model_complexity=MODEL_COMPLEXITY,
        max_num_hands=MAX_HANDS,
        min_detection_confidence=DETECT_CONF,
        min_tracking_confidence=TRACK_CONF
    )

    cv2.namedWindow("MediaPipe Hands", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("MediaPipe Hands", 960, 540)

    t0, frames = time.time(), 0
    print("âœ… è¿è¡Œä¸­ï¼šq é€€å‡ºï¼Œf åˆ‡æ¢é•œåƒï¼Œs ä¿å­˜æˆªå›¾ã€‚")

    selfie = True # æ˜¯å¦æ°´å¹³é•œåƒæ˜¾ç¤ºï¼ˆæ›´ç¬¦åˆè‡ªæ‹è§†è§’ï¼‰

    save_idx = 0
    while True:
        ok, frame = cap.read()
        if not ok:
            print("âš ï¸ æ‘„åƒå¤´è¯»å–å¤±è´¥"); break

        if selfie:
            frame = cv2.flip(frame, 1)

        # MediaPipe ä½¿ç”¨ RGB, OpenCV ä½¿ç”¨ BGR
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # è½¬æ¢é¢œè‰²ç©ºé—´
        rgb.flags.writeable = False 
        results = hands.process(rgb)
        rgb.flags.writeable = True

        # ç»˜åˆ¶å…³é”®ç‚¹
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # é€šè¿‡ MediaPipe è‡ªå¸¦çš„ç»˜å›¾æ ·å¼ç»˜åˆ¶
                mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_styles.get_default_hand_landmarks_style(),
                    mp_styles.get_default_hand_connections_style()
                )

            # ä¹Ÿå¯ä»¥æŠŠæ•°æ®ç»“æ„åŒ–ï¼ˆä¸ºæ¥ Unity åšå‡†å¤‡ï¼‰
            h, w = frame.shape[:2] # å›¾åƒå°ºå¯¸
            all_hands = [landmarks_to_list(lm, w, h) for lm in results.multi_hand_landmarks] # ç»“æ„åŒ–æ‰‹éƒ¨å…³é”®ç‚¹
            # TODO: å‘é€ all_hands é€šè¿‡ WebSocket åˆ° Unityï¼ˆåç»­å†æ¥ï¼‰

        draw_handedness(frame, results) # ç»˜åˆ¶å·¦å³æ‰‹æ ‡æ³¨

        # è®¡ç®— FPSï¼ˆæ›´å¯ä¿¡çš„æ–¹å¼ï¼šæµ‹ 60 å¸§æ—¶é—´ï¼‰
        frames += 1
        dt = time.time() - t0
        if dt >= 0.5:
            fps = frames / dt
            t0, frames = time.time(), 0
        else:
            fps = float('nan')
        if fps == fps:  # é NaN
            draw_fps(frame, fps)

        cv2.imshow("MediaPipe Hands", frame)
        k = cv2.waitKey(1) & 0xFF
        if k == ord('q'): break
        elif k == ord('f'):
            selfie = not selfie
            print("é•œåƒï¼š", "å¼€" if selfie else "å…³")
        elif k == ord('s'):
            cv2.imwrite(f"hands_{save_idx}.png", frame)
            print(f"ğŸ’¾ å·²ä¿å­˜ hands_{save_idx}.png")
            save_idx += 1

    hands.close()
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
